{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4a9a97e0",
      "metadata": {
        "id": "4a9a97e0"
      },
      "source": [
        "# APIs ‚Äî Hands‚Äëon with Python\n",
        "This Colab walks you through three live API calls:\n",
        "1. Weather forecast\n",
        "2. Cat facts\n",
        "3. OpenAI Chat Completions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ installation"
      ],
      "metadata": {
        "id": "gcZTDV5CBHrk"
      },
      "id": "gcZTDV5CBHrk"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fa969b2b",
      "metadata": {
        "id": "fa969b2b"
      },
      "outputs": [],
      "source": [
        "!pip -q install requests google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì¶ Imports"
      ],
      "metadata": {
        "id": "d1CPo0lHIwni"
      },
      "id": "d1CPo0lHIwni"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7f5d5582",
      "metadata": {
        "id": "7f5d5582"
      },
      "outputs": [],
      "source": [
        "import requests, pprint\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dca3b817",
      "metadata": {
        "id": "dca3b817"
      },
      "source": [
        "##  ‚öôÔ∏è 1. Get current weather for London (Simple api call )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://api.open-meteo.com/v1/forecast?latitude=51.5&longitude=-0.12&current_weather=true\"\n",
        "resp = requests.get(url, timeout=10)\n",
        "resp.raise_for_status()\n",
        "weather = resp.json()\n",
        "pprint.pp(weather)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w36xxy0hI0Lh",
        "outputId": "2738de22-466d-44f7-a092-1b8afc858123"
      },
      "id": "w36xxy0hI0Lh",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'latitude': 51.5,\n",
            " 'longitude': -0.120000124,\n",
            " 'generationtime_ms': 0.08487701416015625,\n",
            " 'utc_offset_seconds': 0,\n",
            " 'timezone': 'GMT',\n",
            " 'timezone_abbreviation': 'GMT',\n",
            " 'elevation': 1.0,\n",
            " 'current_weather_units': {'time': 'iso8601',\n",
            "                           'interval': 'seconds',\n",
            "                           'temperature': '¬∞C',\n",
            "                           'windspeed': 'km/h',\n",
            "                           'winddirection': '¬∞',\n",
            "                           'is_day': '',\n",
            "                           'weathercode': 'wmo code'},\n",
            " 'current_weather': {'time': '2025-08-13T08:45',\n",
            "                     'interval': 900,\n",
            "                     'temperature': 21.0,\n",
            "                     'windspeed': 8.1,\n",
            "                     'winddirection': 201,\n",
            "                     'is_day': 1,\n",
            "                     'weathercode': 3}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43e226af",
      "metadata": {
        "id": "43e226af"
      },
      "source": [
        "## ‚öôÔ∏è 2. Swap endpoint: Cat Fact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d1a75b24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1a75b24",
        "outputId": "aa6fe589-dd5e-48de-94ef-a148b827e842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A cat rubs against people not only to be affectionate but also to mark out its territory with scent glands around its face. The tail area and paws also carry the cat‚Äôs scent.\n"
          ]
        }
      ],
      "source": [
        "url = \"https://catfact.ninja/fact\"\n",
        "resp = requests.get(url, timeout=10)\n",
        "resp.raise_for_status()\n",
        "print(resp.json()['fact'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b531c0bf",
      "metadata": {
        "id": "b531c0bf"
      },
      "source": [
        "## 3. üîê Load API Key\n",
        "Fill in your API key below. You can store it in an environment variable or directly in the code (not recommended for production)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "LzAes2NNygH-"
      },
      "id": "LzAes2NNygH-",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking Behavior - Stateless or Stateful"
      ],
      "metadata": {
        "id": "27Ie3wbFBel_"
      },
      "id": "27Ie3wbFBel_"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2d2be137",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "2d2be137",
        "outputId": "af0c72d1-0a91-4887-946a-2ce52bd0cdaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Wania! It's nice to meet you!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# üîë TODO: Replace with your own key or set OPENAI_API_KEY in the environment\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "genai.configure(api_key=gemini_api_key)\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.5-flash') # Using a preview version\n",
        "\n",
        "response = model.generate_content(\"Say hello! I'm Wania\")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "response = response.generate_content(\"what's my name?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "1FIPkwn9zd1i",
        "outputId": "b3bf6332-b146-4050-9986-ca42538ef78b"
      },
      "id": "1FIPkwn9zd1i",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an AI, I don't have access to your personal information, so I don't know your name. I don't retain any details about individual users.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Responses API\n"
      ],
      "metadata": {
        "id": "TTDSEFOEzmmp"
      },
      "id": "TTDSEFOEzmmp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking Behavior - Stateless or Stateful"
      ],
      "metadata": {
        "id": "orQ1nnIvBwIe"
      },
      "id": "orQ1nnIvBwIe"
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.5-flash') # Use a model that supports multimodal input\n",
        "\n",
        "response = model.generate_content([\n",
        "    \"what is in this image?\",\n",
        "    {\n",
        "        \"mime_type\": \"image/jpeg\",\n",
        "        \"data\": requests.get(\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\").content\n",
        "    }\n",
        "])\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "QvbonFkyzj0A",
        "outputId": "873fcffc-d663-4b00-9a73-20aa7be6a5e6"
      },
      "id": "QvbonFkyzj0A",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This image depicts a **scenic natural landscape** featuring a **wooden boardwalk** cutting through a vast, vibrant **green field**.\n",
            "\n",
            "Here's a more detailed breakdown:\n",
            "\n",
            "*   **Foreground and Midground:** A light-colored, weathered wooden boardwalk extends from the bottom center of the image and recedes into the distance, guiding the viewer's eye. On both sides of the boardwalk, tall, lush green grass dominates the scene, appearing dense and catching the sunlight with a bright, almost luminous quality. Some of the grass stalks have a slightly golden or straw-like hue, indicating maturity or how they interact with the light.\n",
            "*   **Background:** In the mid-distance, a line of trees and bushes forms the horizon. These include various shades of green foliage, with some areas, particularly on the right side, showing reddish-brown or autumnal tones in the dense shrubbery.\n",
            "*   **Sky:** The upper portion of the image is filled with a wide, bright blue sky. Scattered across the sky are wispy, elongated white clouds, suggesting a clear day with some atmospheric movement.\n",
            "*   **Lighting:** The lighting appears soft and warm, suggesting either late afternoon or early morning, with the sun illuminating the grass and the boardwalk.\n",
            "\n",
            "Overall, it's a peaceful and inviting natural scene, likely a path through a meadow, wetland, or nature reserve.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "client = genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "response = model.generate_content(\"hello, I'm Wania\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "5ZyYfvcv0hbL",
        "outputId": "d378c6f6-8510-46b8-ae9c-f15575a735cf"
      },
      "id": "5ZyYfvcv0hbL",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Wania! It's nice to meet you.\n",
            "\n",
            "How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_response = client.responses.create(\n",
        "    model=\"gpt-4.1\",\n",
        "    store=True,\n",
        "    previous_response_id=response.id,  # üëà linking to earlier message\n",
        "    input=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                { \"type\": \"input_text\", \"text\": \"What is my name?\" },\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Follow-up response:\", next_response.output[0].content[0].text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "2oIgMo_k1xUe",
        "outputId": "03f9da64-01ba-449f-f319-8e665d61f868"
      },
      "id": "2oIgMo_k1xUe",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'client' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2012039933.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m next_response = client.responses.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gemini-2.5-flash\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprevious_response_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# üëà linking to earlier message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     input=[\n",
            "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üòä Gemini Code"
      ],
      "metadata": {
        "id": "naMFaJHPFvJA"
      },
      "id": "naMFaJHPFvJA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì¶ Imports"
      ],
      "metadata": {
        "id": "ZIA6rLuOEhj5"
      },
      "id": "ZIA6rLuOEhj5"
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "IwbuyW5wDlJa"
      },
      "id": "IwbuyW5wDlJa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîê Load API Key"
      ],
      "metadata": {
        "id": "_p4GZAVmDv6Y"
      },
      "id": "_p4GZAVmDv6Y"
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "FpkOZ-w6D2hJ"
      },
      "id": "FpkOZ-w6D2hJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Initialize Gemini Client"
      ],
      "metadata": {
        "id": "rfJF3kT2EAtZ"
      },
      "id": "rfJF3kT2EAtZ"
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    api_key=api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")"
      ],
      "metadata": {
        "id": "W42Ax6PKEDho"
      },
      "id": "W42Ax6PKEDho",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí¨ Run Basic Chat Completion"
      ],
      "metadata": {
        "id": "9XmnFS-NEGrI"
      },
      "id": "9XmnFS-NEGrI"
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"üß† Asking Gemini a question...\\n\")\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\",   \"content\": \"Explain how AI works in simple terms.\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    message = response.choices[0].message.content\n",
        "    print(\"üí° Gemini's Response:\\n\")\n",
        "    print(message)"
      ],
      "metadata": {
        "id": "TcM49HaSEJ3Q"
      },
      "id": "TcM49HaSEJ3Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Entry Point"
      ],
      "metadata": {
        "id": "qx0Lsqj5EUdg"
      },
      "id": "qx0Lsqj5EUdg"
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6PQQa55EOAZ",
        "outputId": "9f5df7a1-3956-42e8-eeaf-01022f791b24"
      },
      "id": "-6PQQa55EOAZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Asking Gemini a question...\n",
            "\n",
            "üí° Gemini's Response:\n",
            "\n",
            "Imagine you want to teach a computer to tell the difference between a cat and a dog.\n",
            "\n",
            "Here's how AI essentially works, simplified:\n",
            "\n",
            "1.  **Show and Tell (Training Data):**\n",
            "    You don't just tell the computer \"This is a cat.\" Instead, you show it *thousands* (or even millions) of pictures of cats, and for each one, you label it \"cat.\" You do the same with dogs, labeling them \"dog.\" This massive collection of labeled examples is called **training data**.\n",
            "\n",
            "2.  **Pattern Recognition (Learning Algorithms):**\n",
            "    The AI isn't like a human brain. It's more like a very powerful pattern-finding machine. It looks at all these pictures and starts to figure out what common features belong to cats (pointy ears, certain eye shapes, whiskers, etc.) and what belongs to dogs (floppy ears, different snout shapes, etc.). It builds its own internal \"rules\" or \"understanding\" based on these patterns. These \"rules\" are developed by **algorithms**, which are just very smart sets of instructions.\n",
            "\n",
            "3.  **Making a Guess (Prediction):**\n",
            "    Once the AI has \"learned\" from all the training data, you can show it a *brand-new picture* it's never seen before. Based on the patterns it found during training, it will make a guess: \"I think this is a cat\" or \"I think this is a dog.\" The more data it sees and the better its algorithms, the more accurate its guesses will be.\n",
            "\n",
            "**Think of it like this:**\n",
            "\n",
            "*   **Data:** Is the \"food\" the AI eats. The more diverse and relevant the food, the better it learns.\n",
            "*   **Algorithms:** Are the \"recipes\" or \"instruction manuals\" that tell the AI how to process that food and find patterns.\n",
            "*   **Learning:** Is the process of the AI adjusting its internal \"rules\" based on the data to get better at its task.\n",
            "\n",
            "**In essence, AI is about:**\n",
            "\n",
            "*   **Feeding computers vast amounts of data.**\n",
            "*   **Using clever programs (algorithms) to find patterns and relationships in that data.**\n",
            "*   **Allowing the computer to use those patterns to make predictions, decisions, or perform tasks without being explicitly programmed for every single scenario.**\n",
            "\n",
            "It's not \"thinking\" or \"conscious\" like a human, but it's incredibly good at finding complex patterns and acting on them.\n",
            "\n",
            "**Examples you might encounter:**\n",
            "\n",
            "*   **Siri or Alexa:** Trained on millions of voice recordings to recognize your words and understand commands.\n",
            "*   **Netflix recommendations:** Trained on your viewing history and what similar users watch to suggest new movies.\n",
            "*   **Self-driving cars:** Trained on countless hours of driving data, road signs, and object recognition to navigate.\n",
            "*   **Spam filters:** Trained on examples of spam and legitimate emails to identify unwanted messages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "818cf8ca",
        "outputId": "e521bda0-264c-46b1-9252-e2a2b6149116"
      },
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "id": "818cf8ca",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-flash-lite-preview-06-17\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-2.5-flash-lite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "c0457f66",
        "outputId": "4369c29e-19a2-4433-9176-513f8e819a26"
      },
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "# Start a new chat session\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "# Send the first message\n",
        "response1 = chat.send_message(\"hello, I'm Wania\")\n",
        "print(\"First response:\", response1.text)\n",
        "\n",
        "# Now, in a separate cell or later in this cell, you can send a follow-up message using the same 'chat' object\n",
        "# For example, in a new cell, you would use:\n",
        "# response2 = chat.send_message(\"What is my name?\")\n",
        "# print(\"Second response:\", response2.text)"
      ],
      "id": "c0457f66",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First response: Hello Wania! It's nice to meet you. I'm a large language model, here to help you. How can I assist you today?\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}